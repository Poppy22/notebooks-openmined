{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2fdd84-96be-4c5e-87ab-4276f0bdd17a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206f6e0-91e1-44c3-ae65-0acb3058dcd7",
   "metadata": {},
   "source": [
    "Welcome ðŸ‘‹!\n",
    "\n",
    "First of all, thank you for helping the world become more privacy-friendly by using PySyft. This notebook is primarily intended for **data scientists** and it will guide you into how to make use of all the capabilities PySyft has to offer in the latest version 0.8.\n",
    "\n",
    "This tutorial will cover five parts:\\\n",
    "(1) ðŸ‘‰ Understanding the workflow\\\n",
    "(2) ðŸ‘‰ Understanding the dataset\\\n",
    "(3) ðŸ‘‰ Writing a code request\\\n",
    "(4) ðŸ‘‰ Sending a code request\\\n",
    "(5) ðŸ‘‰ What queries are supported in syft 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7086bb-61e0-4017-96a5-e25eb951c90d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 1 - Understanding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424118e-579d-4995-900e-eef574ee3e6f",
   "metadata": {},
   "source": [
    "#### Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a72b379-f686-4096-9487-2b6e8102bdf4",
   "metadata": {},
   "source": [
    "You would like to pursue research in the field of algorithmic transparency to protect the rights of social media users. We collaborated with private companies that made available via PySyft an initial set of datasets to enable such research.\n",
    "\n",
    "They will provide access to their data, as explained below. At this stage, you should have received an URL and credential information (email and password) from a designated data manager. A data manager is a company representative who will collaborate with you to provide access to the data.\n",
    "\n",
    "Without the credentials, you cannot login into PySyft API or platform, and thus cannot carry out your research tasks. Please reach out to the data managers if you have not received instructions about logging in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ce136-38b7-49d5-9208-0f4d3b2cec61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The role of data managers\n",
    "Data managers are PySyft users on behalf of companies, who are responsible for datasets. They can upload, edit and remove datasets. Most importantly, a data manager is the person who will share the login credentials with you in the first place, and and who will approve your code requests (also named code queries, or code submissions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b514164-a6bf-4d11-b48b-b709dc5a7669",
   "metadata": {},
   "source": [
    "#### Code request\n",
    "Once you receive your credentials to log into the domain, you will be able to submit code queries, which will allow you to learn from the data. A code query can be seen as a function which will give you a desired answer (for example, the average rating for a post type, the highest/lowest value with specific criteria etc). We'll see how to work with code queries in parts 3 and 4 of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf20ba6-cdef-4cd5-81e2-21e66897fbcd",
   "metadata": {},
   "source": [
    "#### However...\n",
    "\n",
    "You won't directly have access to the private data. This is convenient for data managers, as they retain ownership of the data and prevent it from getting copied elsewhere. However, you will still be able to learn relevant statistical information from the dataset, even without having access to the data per se. This is good for data scientists like you, as you can still make use of the knowledge contained in the dataset and be able to advance your research. Win-win!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892610b3-897e-4ccf-9c3f-22ff8ce0b362",
   "metadata": {},
   "source": [
    "#### Real data and mock data\n",
    "\n",
    "How it works is that there will be two datasets:\n",
    "- the real dataset, containing the true unaltered information\n",
    "- a mock dataset, containing fake data generated to be of the same type and shape to the real one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9b001-1e4a-4a1b-b0c3-3e135ff97f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### High-side domain and low-side domain\n",
    "\n",
    "The real dataset will be kept private in what is called **the high side domain**. Only the data manager or other company employess will have direct access to it, and not data scientists.\n",
    "\n",
    "The mock dataset will be stored into the **low side domain** and you will have direct access to it via code request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32cf997-ec52-4689-a34c-3f07cc652aa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Workflow altogether\n",
    "\n",
    "Let's assume the data manager approved your project request to study the dataset, and now you can start learning from it via code requests.\n",
    "\n",
    "**Decide on a research question**\\\n",
    "First, what question do you want to answer? Let's imagine that you want the average number of reactions for a social media post of a certain type.\n",
    "\n",
    "**Prepare the query** (purple arrows)\\\n",
    "Once you know your goal, you will start by preparing the query. You will only work on the mock dataset, the one from the low-side domain. The dataset will look and feel like the real one, but it won't contain the true data. You can make use of this to write and test your query, to make sure that the code compiles properly and returns an answer. You can edit and test your code query locally as many times as you want.\n",
    "\n",
    "**Submit the code request** (orange arrows)\\\n",
    "Once you are happy with the code query, then you can send it to be run on the real data. This is how you will get an accurate (but still privacy-friendly) answer for your research question. What happens here is that your code will be sent via PySyft API directly to the data manager. The data manager will check your code, make sure it is safe to be run on the real data, and if so, then they will execute your code on the private data, and generate the answer. This is why it's important that your code runs correctly when you decide to submit the code request - otherwise, the data manager will also be unable to run it and this will result in delays. \n",
    "\n",
    "**Get the answer** (orange arrows)\\\n",
    "After the data manager runs the code, they will also inspect the answer to make sure privacy is preserved if they share it with you. If all is fine, then they will send you the unaltered answer which your function returned on the private, real data this time. You will be notified when the answer is ready and will be able to retrieve this using the PySyft API.\n",
    "\n",
    "All the technical details will be explained in this tutorial, in parts 3 and 4.\n",
    "\n",
    "**Imporatant note**: Because getting the real answer involves manual checks and execution on behalf of the data manager, this means that often the data scientist won't receive the answer right away, but it might be hours or even days later. We know that this is not ideal, but as privacy enhancing techniques become more mature, and as your organisation trusts them more and more, the whole workflow will simplify and the steps in between your query and getting the result will reduce. This advanced level of accessibility and convenience in doing remote data science, while maintaining privacy, is at the core of OpenMined's mission - this is what we are pushing for, and, right now, you are a pioneer of this technology, helping us bring it forward through your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3409955-27d8-499e-a50b-668c8fa4d6d6",
   "metadata": {},
   "source": [
    "![Screenshot 2023-04-26 at 22.23.04.png](level-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dab03d-8817-46d8-895d-fd61026f0c7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 2 - Understanding the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337fdf9-c5b8-4e16-961f-9252669ea11d",
   "metadata": {},
   "source": [
    "So many of the technical solutions which we use on a day to day basis (including social media platforms) make use of AI algorithms in the decisions that they make. As such, it is increasingly important to be able to question, understand and explain how these algorithms work (algorithmic transparency), and to be able to answer ethical questions (for example, to prove or disprove if an AI algorithm shows any signs of bias towards a minority group, in order to mitigate the risks posed for that group). But to achieve this, we need relevant data gathered on a topic, and skilled scientists to derive conclusions out of it.\n",
    "\n",
    "In writing this tutorial, we assume the motivation of **advancing algorithmic transparency** in this research project, and as such, the dataset will be relevant for this purpose.\n",
    "\n",
    "The inspiration from this project is a study run by Twitter to examine the effects of machine learning on the amplification of political content from elected officials or news outlets. Their paper can be found [here](https://www.pnas.org/doi/full/10.1073/pnas.2025334119)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f945dc-d7f6-4e64-99ad-fe6fc411d4a9",
   "metadata": {},
   "source": [
    "**Study summary**\\\n",
    "Personalization algorithms play an important role in how the content on the Twitter timeline is selected and ordered, which can lead to amplification or suppression of certain messages. To assess whether some political groups benefit from this more than others and whether this results in a preferential treatment due to algorithm internals rather than the interactions, Twitter ran an in-depth study comparing the algorithmically ranked Home timeline versus the reverse chronological Home timeline.\n",
    "\n",
    "The study was carried out during March - June 2020, and targeted only 5% of the twitter users, as such:\n",
    "- 4% of the users were placed in the **treatment group**, meaning that they experienced the **algorithmically ranked Home timeline**\n",
    "- 1% of the users were placed in the **control group**, meaning that they experienced the **reverse chronological Home timeline**\n",
    "- the rest 95% of the Twitter users were not part of the study\n",
    "- the users placed in the treatment and in the control group were randomly selected\n",
    "\n",
    "The dataset has the following form:\n",
    "| Tweet ID | Link      | Impression | Bucket    | ... |\n",
    "|----------|-----------|------------|-----------|-----|\n",
    "| id1      | news.ca/a | 100        | Control   |     |\n",
    "| id2      | news.ca/a | 150        | Treatment |     |\n",
    "| id3      | news.ca/b | 205        | Control   |     |\n",
    "| id4      | news.ca/b | 178        | Treatment |     |\n",
    "| ...      |           |            |           |     |\n",
    "\n",
    "It records the number of impressions (in this case, the number of views) for a specific post, both from the control group and from the treatment group.\n",
    "\n",
    "Of course, the idea of the study can be extended to any type of data. In this example, we can replace `tweets` with any other object recommended to the user, such as pictures, videos, reels, items to purchase etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1984029-fccf-4aaa-8770-454c946fcca0",
   "metadata": {},
   "source": [
    "Next, we will work with an imaginary dataset to show the abilities of the PySyft library. Following the Twitter study above, let's imagine that there exists a social media platform where users can only post images which contain bubble tea drinks. Each picture has a link that takes the user to an online bubble tea store, where they can order the particular drink featured in the image. Impressions, in this example, are measured by the number of clicks on the link in each picture.\n",
    "\n",
    "The form of the dataset is as such:\n",
    "| PostId   | Link      | Impression | Bucket    | ... |\n",
    "|----------|-----------|------------|-----------|-----|\n",
    "| id1      | bt/brown-sugar1 | 10        | Control   |     |\n",
    "| id2      | bt/brown-sugar1 | 28        | Treatment |     |\n",
    "| id3      | bt/oolong1 | 21        | Control   |     |\n",
    "| id4      | bt/oolong1 | 4        | Treatment |     |\n",
    "| ...      |           |            |           |     |\n",
    "\n",
    "You are trying to identify if the order in which the images are shown influence the purchasing decision of the users. Just like in the Twitter example, there is the control (chronological order) and the treatment group (using a ranking algorithm).\n",
    "\n",
    "You have access to this dataset on the low-side domain hosted by the company. Their private data is on the high-side domain, as explained before, and currently you will work with mock data. We will work with a small example, containing only 6 rows and the four columns from before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65585acf-2ec2-4f01-921b-98ccc9873370",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3 - Writing a code request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380df80b-b847-430e-86f8-76f594ee6e20",
   "metadata": {},
   "source": [
    "You have access to a dataset (with fake data) on which you will prepare the query. Below are the steps you need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a36f1a-da0c-4a4b-808a-a3e1cce02b1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Logging in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c00c7c-3a8d-4afd-a9c2-dfccba04bbf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kj/filesystem-disk-unix.c++:1703: warning: PWD environment variable doesn't match current directory; pwd = /Users/carmenpopa/.hagrid/quickstart\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91426f8-f988-421f-be70-22254083ca8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged into Nice Bach as <ana.banana@uni.org>\n"
     ]
    }
   ],
   "source": [
    "# change the url, and your email and password with your own credentials\n",
    "\n",
    "guest_domain_client = sy.login(url='http://localhost:8081', email='ana.banana@uni.org', password='student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5304056-15c1-43b9-a4d5-52581c4916a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SyftClient - Nice Bach <9af5795ca6b1447cafaced0bfbe2eca3>: HTTPConnection: http://localhost:8081>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guest_domain_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685eacab-9cec-4ec1-b48b-fd2ff86fb944",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Access the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6321e066-070e-4776-96de-308866242ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "List - Size: 1\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syft.service.dataset.dataset.Dataset</td>\n",
       "      <td>575c017e652140369133196d432102b4</td>\n",
       "      <td>Algorithmic study - Bubble tea mock data</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<syft.client.api.APIModule at 0x179ac2c20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see a list of all available datasets! For now, it will be just one, the bubble tea mock data described above.\n",
    "\n",
    "guest_domain_client.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c28d43-b661-45fd-8f34-7d667a3062d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can directly access one of the datasets in the list, let's save it in a variable.\n",
    "\n",
    "dataset = guest_domain_client.datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f205f1cc-fd83-4272-9678-7f20403b82e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "Syft Dataset: Algorithmic study - Bubble tea mock data\n",
       "Assets:\n",
       "\tbubble_tea_data_model_auditing: Mock data for bubble tea social media study\n",
       "Citation: Carmen Popa\n",
       "Description: The fake dataset for the bubble tea algorithmic study\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "syft.service.dataset.dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see all the class fields (metadata added by the data owner) of the dataset.\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aca856-93b0-4021-b0fb-5f3c9ec43c22",
   "metadata": {
    "tags": []
   },
   "source": [
    "**About assets**\\\n",
    "PySyft library provides flexibility so that data owners can group together assets into a single dataset. As such, a dataset is a collection of assets, and each asset is a singular object which holds the data. For example, one can add the same data in multiple formats, but use a single uploaded dataset, with more assets (one asset for each format of the data). Similarly, one can split the dataset into testing / training / validation, and use assets to mark this.\n",
    "\n",
    "For our current example, the dataset has just one asset, as shown below. But it might be that a dataset contains multiple assets, and their meaning or difference will be marked in the `key` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d424cc7-f813-41e8-9cc8-00c6e2bb8c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tupledict - Size: 1\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bubble_tea_data_model_auditing</td>\n",
       "      <td>syft.service.dataset.dataset.Asset</td>\n",
       "      <td>0d5710b409d54b10b6293bd6a1d70929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "TupleDict([('bubble_tea_data_model_auditing',\n",
       "            syft.service.dataset.dataset.Asset)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkout the assets of the dataset; in the list below, there is just one asset available.\n",
    "\n",
    "dataset.assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a7169e-be88-4dc0-8cb7-6aa051f4a698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'syft.service.dataset.dataset.Dataset'>\n",
      "<class 'syft.service.dataset.dataset.Asset'>\n",
      "<class 'syft.service.action.pandas.PandasDataFrameObject'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# The PySyft dataset has multiple wrappers around the core pandas dataframe object.\n",
    "# To work with the data, you should extract it as explained below:\n",
    "\n",
    "print(type(dataset))\n",
    "print(type(dataset.assets[0]))\n",
    "print(type(dataset.assets[0].mock))  # ---> this is the dataset which needs to be passed to the code submission; it's the Syft object that holds the data\n",
    "print(type(dataset.assets[0].mock.syft_action_data))  # ---> this is the dataframe which you can use locally; it's the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88ec8ec-d906-4552-9309-135c1d972640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's access the Pandas dataframe. You can work with this object like with any other dataframe.\n",
    "# You can access the shape, print some rows, get statistical results on the columns, split the dataset etc.\n",
    "\n",
    "mock_df = dataset.assets[0].mock.syft_action_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2af41d1-8f54-4462-b0dc-7993d98d3918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9bd862-9ea6-4037-9300-48e37f8cd06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>Link</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id1</td>\n",
       "      <td>bt/brown-sugar1</td>\n",
       "      <td>120</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2</td>\n",
       "      <td>bt/brown-sugar1</td>\n",
       "      <td>275</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3</td>\n",
       "      <td>bt/oolong1</td>\n",
       "      <td>181</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id4</td>\n",
       "      <td>bt/oolong1</td>\n",
       "      <td>49</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id5</td>\n",
       "      <td>bt/taro1</td>\n",
       "      <td>122</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PostId             Link  Impression     Bucket\n",
       "0    id1  bt/brown-sugar1         120    Control\n",
       "1    id2  bt/brown-sugar1         275  Treatment\n",
       "2    id3       bt/oolong1         181    Control\n",
       "3    id4       bt/oolong1          49  Treatment\n",
       "4    id5         bt/taro1         122    Control"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4272ad4a-d413-4d7e-8143-a5e9d11f6783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of impressions: 885\n"
     ]
    }
   ],
   "source": [
    "print('Total number of impressions:', mock_df[\"Impression\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74149776-975e-408c-9654-1a7920abbc20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>Link</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id1</td>\n",
       "      <td>bt/brown-sugar1</td>\n",
       "      <td>120</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2</td>\n",
       "      <td>bt/brown-sugar1</td>\n",
       "      <td>275</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PostId             Link  Impression     Bucket\n",
       "0    id1  bt/brown-sugar1         120    Control\n",
       "1    id2  bt/brown-sugar1         275  Treatment"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b06fd-3b4d-49af-acd0-aef6c523666c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Query for mock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fdf4a-84e7-43ed-9f62-399bc173ccbd",
   "metadata": {},
   "source": [
    "Now that you can access the dataset, let's try to answer some ethical questions based on the data. Let's consider the example in which you want to query the average number of impressions for the Treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9309f81e-76c9-4672-a0c9-93f9fa45ba99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result on the mock dataset\n",
    "\n",
    "mock_df[mock_df['Bucket'] == 'Treatment']['Impression'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6903046-3ac6-480e-aa91-654e74fff845",
   "metadata": {},
   "source": [
    "But this is the answer computed on the mock data. As explained before, you need to submit a function (code request) which will be run on the private data to obtain the real result. \n",
    "\n",
    "The template below is a good start for this function. It has a **syft annotation**, which specifies the **input policy** and the **output policy**.\n",
    "\n",
    "Input and Output Polices are rules set by the data owner on what data can go IN and what data can come OUT of custom code. These policies basically pair up the code submission with the dataset asset it was intended for.\n",
    "\n",
    "The input policy gives the data owner the confidence that the system will only allow the code to run on the specified asset from the dataset (i.e. `ExactMatch(bubble_tea_data=mock)`). This means that an approved code cannot be run on any asset at random.\n",
    "\n",
    "Output policies are used to maintain state, meaning they can remember between execution. They are useful to imposing limits such as allowing an execution of a code only for 10 times. This allows a data owner to have confidence on how many times and what the output structure looks like when that custom code is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "301e589b-13f0-40a6-a70b-2b1564ff506c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracting the PySyft object which holds the dataset, to pass it to the code submission below\n",
    "\n",
    "mock = dataset.assets[0].mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb89b312-8f21-46ac-b85c-530871d93cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the parameter name needs to match the argument name specified in the input policy (e.g. `bubble_tea_data`)\n",
    "\n",
    "@sy.syft_function(input_policy=sy.ExactMatch(bubble_tea_data=mock),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def average_impression_treatment_query_v1(bubble_tea_data):\n",
    "    # customize your query here\n",
    "    \n",
    "    df = bubble_tea_data\n",
    "    result = df[df['Bucket'] == 'Treatment']['Impression'].mean()\n",
    "    \n",
    "    return float(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd602c5-cb5d-448c-b1c4-150e2a97c7c3",
   "metadata": {},
   "source": [
    "*Note: The system will not restrain you from submitting a function with the same name, as long as the code within is different. However, we recommend adding version identifiers to your function name (e.g. `_v1` used above) to be able to identify between multiple submissions. You might want to change the query at some point, or to correct something in your query after you already submit it. If you use the same  function name, it might be hard to identify which is that particular version of the code, because they will all appear under the same name, and then you might now know which returned result is the one you were looking for. Thus, we suggest having different names depending on the version of the code. So basically, for every submission, increment the number of the version.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1103b04b-74ac-44bb-90e2-22b8f98fc95d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the use of mock (PySyft object) instead of mock_df (Pandas dataframe)\n",
    "\n",
    "result = average_impression_treatment_query_v1(bubble_tea_data=mock)\n",
    "result  # should be the same one as the one you tested locally (e.g. 154 for the current example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d72e27-a6b1-4678-b377-9dbff00e8c31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109ad7d-d4f5-4462-afe0-c9ef4b6976e8",
   "metadata": {},
   "source": [
    "As we can see from the code, `average_impression_treatment_query_v1` returns the result as it is. This function will also be run on the private data, which means that it will return then exact average that is computed on the private data.\n",
    "\n",
    "In some cases, this might not be accepted by the data owner due to privacy reasons. Without any alterations in the computed result, you can, for example, make multiple slighlty different queries and then infer private information about the subjects, which infringes their privacy. As such, adding some noise to the result is needed.\n",
    "\n",
    "Ideally, this would be taken care of automatically by PySyft library, or by the data manager, making sure that they do not send to you the exact real result. However, currently, this is not supported, and the proposed workflow is that the data scientist will add the noise in their request.\n",
    "\n",
    "In your work, it might be that for some datasets, it is not needed to add any noise. This depends on the nature of the data, and on the privacy requirements imposed by the data owners. However, for some datasets, adding noise to a result might be mandatory, and a query like the one above will be rejected.\n",
    "\n",
    "If you need to add noise to your result, you can make use of data privacy engines, such as the [OpenDP](https://docs.opendp.org/en/stable/index.html) open-source library.\n",
    "\n",
    "Next, we will write a new version of the function (`average_impression_treatment_noise_query_v1`), which still computes the average number of impressions for the Treatment group, but adds noise to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc4c1c9-298d-4bad-9582-e40d5ccff6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenDP documentation for mean: \n",
    "# https://docs.opendp.org/en/stable/user/transformations/aggregation-mean.html\n",
    "\n",
    "@sy.syft_function(input_policy=sy.ExactMatch(bubble_tea_data=mock),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def average_impression_treatment_noise_query_v1(bubble_tea_data):\n",
    "    # imports\n",
    "    from opendp.mod import enable_features\n",
    "    from opendp.measurements import make_base_laplace\n",
    "    enable_features('contrib')\n",
    "    \n",
    "    # generate noise\n",
    "    aggregate = 0.\n",
    "    base_lap = make_base_laplace(scale=5.)\n",
    "    noise = base_lap(aggregate)\n",
    "\n",
    "    # customize your query here\n",
    "    df = bubble_tea_data\n",
    "    result = df[df['Bucket'] == 'Treatment']['Impression'].mean()\n",
    "    \n",
    "    # return the result with noise\n",
    "    return float(result) + float(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a6194f-9d82-4ee6-b3af-c28bad4796a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.46826112023587"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_with_noise = average_impression_treatment_noise_query_v1(bubble_tea_data=mock)\n",
    "result_with_noise  # try running it multiple times and see how the result changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b855f-3bb7-4bd6-ae1b-e516d314bc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Things to keep in mind when writing functions\n",
    "\n",
    "Remember that you can only test your function locally on the mock dataset, but you are not able to run it yourself on the dataset with the real data. So there might be cases when your function works just fine locally, but the data manager is not able to run it successfully on the real data. To minimize these, write your queries as generic as possible. For example, if you make use of the size of the dataset (number of lines, number of columns), then it's better to compute it inside the function using the Pandas methods for this (`.shape, len()`), than to hardcode it based on the values given by the mock dataset. As a rule of thumb, try to not hardcode things which you can just compute on the input dataset, as this will certainly help having your query generic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f7553-8b99-450c-8de5-a312c9c2749f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### [Good practice] exploring the function before sending it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f8a02-49ff-44b6-8979-f5cde2a4bc01",
   "metadata": {},
   "source": [
    "These are instructions on how to double-check the settings of your custom function, before sending it to be approved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70490122-f3ad-4f34-a843-167b5e51d66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "{NodeView(node_name=&#x27;Nice Bach&#x27;, verify_key=24a243dbb231e9206606260a67069565cf21610676bc0e24bfda9677256a8f37): {&#x27;bubble_tea_data&#x27;: &lt;UID: cc51b887d2334f00813a8b9cf3570083&gt;}}"
      ],
      "text/plain": [
       "{NodeView(node_name='Nice Bach', verify_key=24a243dbb231e9206606260a67069565cf21610676bc0e24bfda9677256a8f37): {'bubble_tea_data': <UID: cc51b887d2334f00813a8b9cf3570083>}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_impression_treatment_query_v1.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c6dc90c-69dd-459b-87de-d6bbbb41031b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syft.service.policy.policy.ExactMatch"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_impression_treatment_query_v1.input_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da12ac05-301b-4e38-87d0-c4fc6b1161ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syft.service.policy.policy.OutputPolicyExecuteOnce"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_impression_treatment_query_v1.output_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9c2fd43-cd09-4cc3-b01b-952db39ef634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@sy.syft_function(input_policy=sy.ExactMatch(bubble_tea_data=mock),\n",
      "                  output_policy=sy.SingleExecutionExactOutput())\n",
      "def average_impression_treatment_query_v1(bubble_tea_data):\n",
      "    # customize your query here\n",
      "    \n",
      "    df = bubble_tea_data\n",
      "    result = df[df['Bucket'] == 'Treatment']['Impression'].mean()\n",
      "    \n",
      "    return float(result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(average_impression_treatment_query_v1.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399c288-65b2-4ba1-82df-eaca9fdaf636",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 4 - Sending a code request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70026778-2fdd-42bf-ae90-46ea2e318304",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Creating a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147472f-9260-404f-b142-b363deee6518",
   "metadata": {},
   "source": [
    "Now that you understand how to write a code request, the next step is to send it. You will send the request as part of a project, so first, you need to create a project.\n",
    "\n",
    "Within a project, you will be able to send multiple code requests relevant with the scope of the project. In this tutorial, we will send the two code requests (with noise and without noise) in the same project.\n",
    "\n",
    "However, you can only submit one project with the same name. If you try to submit the same project twice, it will show an error due to name clashes. This means that, if you have follow-up requests or if you want to correct something in the previous submission, you will need to create a new project. \n",
    "\n",
    "Rule of thumb: create a project everytime you want to submit one or more code requests. Once submitted, you cannot modify of reuse the project for another submission, currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddadf61f-8525-44b1-be84-7546311d959d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a project\n",
    "\n",
    "new_project = sy.Project(name=\"Research on algorithmic transparency in bubble tea social media posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d0f0b-b333-4cb7-8fdb-6229e7627dd7",
   "metadata": {},
   "source": [
    "One important aspect about the project is the description. It's important here to be specific and clear, and even include relevant links in the description that can help the approver (data owner) get as much insight as possible into your research questions and intention. This will increase the chances of having your project approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ddef74-1cbb-4e7a-bdbf-e27c904a9cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a proper description\n",
    "\n",
    "proj_desc = \"\"\"Hello, I want to explore the average number of impressions from the treatment group in this dataset. This will help me see how ...\"\"\"\n",
    "new_project.set_description(proj_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd41fe4e-4e84-4318-b17b-5a62ba59a4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class Request:\n",
       "  id: str = fbd55358ec45424ca4df42bb8355c4d1\n",
       "  requesting_user_verify_key: str = 7a7adf41e1306099798cf8ceaad88c4b946765966ca71c5033c68782a4967cf8\n",
       "  approving_user_verify_key: str = None\n",
       "  request_time: str = 2023-05-20 11:22:56\n",
       "  approval_time: str = None\n",
       "  status: str = RequestStatus.PENDING\n",
       "  node_uid: str = 9af5795ca6b1447cafaced0bfbe2eca3\n",
       "  request_hash: str = \"3133cfbfb3833c88efbf3371cb1512be34e3d3801341a846f912f6dd3e5d6b24\"\n",
       "  changes: str = [syft.service.request.request.UserCodeStatusChange]\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "syft.service.request.request.Request"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sent the code to the quest domain. Use the function name to specify which function you want to send.\n",
    "# Note: this is not the proper code submission, that will happen when you submit the project. At this stage,\n",
    "# the data manager will not be able to see your code request, not until you submit the project.\n",
    "\n",
    "guest_domain_client.api.services.code.request_code_execution(average_impression_treatment_query_v1)\n",
    "guest_domain_client.api.services.code.request_code_execution(average_impression_treatment_noise_query_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a07de932-3815-4056-81fe-a2ada1ce054d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "List - Size: 2\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>service_func_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syft.service.code.user_code.UserCode</td>\n",
       "      <td>98fb26d759b048d69cb0d3a165ef5e2f</td>\n",
       "      <td>{NodeView(node_name='Nice Bach', verify_key=24...</td>\n",
       "      <td>average_impression_treatment_query_v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syft.service.code.user_code.UserCode</td>\n",
       "      <td>04c1d81c23e647d9ace1aafd6650f035</td>\n",
       "      <td>{NodeView(node_name='Nice Bach', verify_key=24...</td>\n",
       "      <td>average_impression_treatment_noise_query_v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<syft.client.api.APIModule at 0x17a700f70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can check all the previous code uploads you've made to this domain.\n",
    "# For this tutorial, there will be only two, namely the functions that we wrote before.\n",
    "\n",
    "guest_domain_client.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5430f8d-1c03-43c6-abe7-440e852f357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can pick a specific code submission from the list above by the index and inspect it.\n",
    "\n",
    "submitted_code = guest_domain_client.code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7e788f1-1c44-40dc-b50e-6ee1cdef5d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syft.service.code.user_code.UserCode"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(submitted_code)  # notice the UserCode syft class; this object is needed when adding the request to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1fb3014-3260-4507-8f8c-145aa6a0566b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syft.service.policy.policy.ExactMatch"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitted_code.input_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c57a1e6-1a7c-46e5-95a4-c4a37aae42b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syft.service.policy.policy.OutputPolicyExecuteOnce"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitted_code.output_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71ce57cc-d00a-4aa7-b019-03fce0b90a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@sy.syft_function(input_policy=sy.ExactMatch(bubble_tea_data=mock),\\n                  output_policy=sy.SingleExecutionExactOutput())\\ndef average_impression_treatment_query_v1(bubble_tea_data):\\n    # customize your query here\\n    \\n    df = bubble_tea_data\\n    result = df[df['Bucket'] == 'Treatment']['Impression'].mean()\\n    \\n    return float(result)\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitted_code.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20a81a79-cf9e-453c-8bf0-d50364c1dfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Next, add the code requests to the project (before submitting the project).\n",
    "# Note: for this step, you need to use the objects which have been uploaded to the domain client\n",
    "# This means that refering to the functions as their name is not enough.\n",
    "\n",
    "new_project.add_request(obj=guest_domain_client.code[0], permission=sy.UserCodeStatus.EXECUTE)\n",
    "new_project.add_request(obj=guest_domain_client.code[1], permission=sy.UserCodeStatus.EXECUTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f21ac677-8146-4cfb-9912-4d6998c0e7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class ProjectSubmit:\n",
       "  id: str = None\n",
       "  name: str = \"Research on algorithmic transparency in bubble tea social media posts\"\n",
       "  description: str = \"Hello, I want to explore the average number of impressions from the treatment group in this dataset. This will help me see how ...\"\n",
       "  changes: str = [syft.service.project.project.ObjectPermissionChange, syft.service.project.project.ObjectPermissionChange]\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "syft.service.project.project.ProjectSubmit"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09b88efa-f4ec-4fe5-b892-f46068be2ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "List - Size: 2\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syft.service.project.project.ObjectPermissionC...</td>\n",
       "      <td>e2ebbe8bdbd54c3b93b8a70602fd1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syft.service.project.project.ObjectPermissionC...</td>\n",
       "      <td>6f98ba325bf24f2386994954c56649ee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[syft.service.project.project.ObjectPermissionChange,\n",
       " syft.service.project.project.ObjectPermissionChange]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see a list of the code submissions added\n",
    "\n",
    "new_project.changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c0980f1-41dc-48c2-a9cd-9b441b42f4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Project Submitted</div><br />"
      ],
      "text/plain": [
       "<class 'syft.service.response.SyftSuccess'>: Project Submitted"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit the project\n",
    "\n",
    "guest_domain_client.submit_project(new_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03814ffa-21db-43a7-b655-57fa9d59bbf4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Receiving an answer to your request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a7b07-835e-470a-bb48-cb10c3900be2",
   "metadata": {},
   "source": [
    "Below we'll see how you can obtain an answer from your request. As mentioned before, the code is inspected by a data manager, and then run on the real data. This can take a while to execute, as it invovles manual work. It can be up to a few days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00989f7e-e36f-489c-8d8b-68c9306f7c23",
   "metadata": {},
   "source": [
    "There are three possible answers which you can get:\n",
    "- code still waiting for approval:\n",
    "        `SyftNotReady: Your code is waiting for approval: {NodeView(node_name='Trusting Silver', verify_key=04137bfea77b4c86492df2b9849190bd4a19b7a2833b3c500dd37fef6957615c): }`\n",
    "- code approved: you will see the returned result, i.e. `(157.9, 2.02)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f1ecda-71b9-4b11-a7b0-7338821e97a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "Asset: bubble_tea_data_model_auditing\n",
       "Pointer Id: cc51b887d2334f00813a8b9cf3570083\n",
       "Description: Mock data for bubble tea social media study\n",
       "Total Data Subjects: 0\n",
       "Shape: (6, 4)\n",
       "Contributors: 0\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "syft.service.dataset.dataset.Asset"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check your result, you will need the asset again. This is because the code can be run on one or multiple\n",
    "# assets, as specified in the input policy. Our examples will only accept one input, but it might be that some queries\n",
    "# are supported on multiple inputs. For this, specify which result you are looking for.\n",
    "\n",
    "asset = guest_domain_client.datasets[0].assets[0]\n",
    "asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e86bfe13-c775-40fd-89ef-065962cf9181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And check the code status for the function which you created. TODO - can I add multiple assets?\n",
    "\n",
    "real_result = guest_domain_client.api.services.code.average_impression_treatment_query_v1(bubble_tea_data=asset)\n",
    "real_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23609fc0-6e2f-4b22-8988-76da429d1402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-info\" style=\"padding:5px;\"><strong>SyftNotReady</strong>: <class 'syft.service.code.user_code.UserCode'> Your code is waiting for approval: {NodeView(node_name='Nice Bach', verify_key=24a243dbb231e9206606260a67069565cf21610676bc0e24bfda9677256a8f37): <UserCodeStatus.SUBMITTED: 'submitted'>}</div><br />"
      ],
      "text/plain": [
       "<class 'syft.service.response.SyftNotReady'>: <class 'syft.service.code.user_code.UserCode'> Your code is waiting for approval: {NodeView(node_name='Nice Bach', verify_key=24a243dbb231e9206606260a67069565cf21610676bc0e24bfda9677256a8f37): <UserCodeStatus.SUBMITTED: 'submitted'>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this request, the answer was not provided yet by the data manager\n",
    "\n",
    "real_result = guest_domain_client.api.services.code.average_impression_treatment_noise_query_v1(bubble_tea_data=asset)\n",
    "real_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c5ce1-9c60-49de-837e-33f335656d90",
   "metadata": {},
   "source": [
    "## Part 5 - Queries supported in Syft 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc04e12-ca70-42ca-958c-38e59f2c33bf",
   "metadata": {},
   "source": [
    "This part of the tutorial will briefly outline what is supported and not when using Syft. There are some limitations, as shown below, and this might result in errors when running the code request on the private data. This section will explain what to bear in mind when writing your code request, and how to adapt your code to the current Syft capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b45d91-1897-42cd-a99f-4f518b41fa04",
   "metadata": {},
   "source": [
    "**Important note:**\n",
    "\n",
    "You can work with the dataset in two ways (both before submitting the project and the code request):\n",
    "\n",
    "(1) Fully local:\n",
    "- this is when you inspect the data outside the code request\n",
    "- for this, you should use `dataset.assets[0].mock.syft_action_data` as explained in part 3\n",
    "- the code written as such will use the real NumPy and Pandas libraries, the ones which you have locally, and not the Syft library\n",
    "\n",
    "(2) Low-side domain:\n",
    "- this is when you run the code on the low-side domain, by writing a code request\n",
    "- for this, you should use `dataset.assets[0].mock` as explained in part 3\n",
    "- this will use the code request which you wrote, and as such, will use the Syft library\n",
    "- the behaviour of this function should, in theory, be the same as the behaviour of the submitted function (when it's run on the real data, on the high-side domain)*\n",
    "\n",
    "\\*In theory, the code request on the dataset using method (2) should work when it would also work on the real data, and should fail when it would also fail on the real data. This would be a good indicator when there is something wrong in the code: works via method (2), then it the whole submission should be alright! However, there is a bug in the library which does not guarantee this behaviour at the moment, so in other words, if all is fine when testing method (2), **the code run on the real data can still crash.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd07589-f2d6-438e-b5d7-d49c1bce50ee",
   "metadata": {},
   "source": [
    "**What is supported for NumPy?** TODO\n",
    "\n",
    "- array creation\n",
    "- computing statistical information: `mean`, `std`, `min`, `max` etc\n",
    "- slicing and indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e15d1-7a0c-465a-b0bc-0c78ea2f0fac",
   "metadata": {},
   "source": [
    "Generally, the most common operations for `NumPy` are also supported when using Syft. But here are some things which you should keep in mind when writing a code request:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011bc49-e83e-4f6f-9c56-6c723aa85069",
   "metadata": {},
   "source": [
    "**[1] Converting objects**\n",
    "\n",
    "`np.assarray(mock_object)`, `pd.DataFrame(mock_object)` and `torch.Tensor(mock_object)` will return objects which lose the Syft class associated to them, which is not desired. Avoid using them.\n",
    "\n",
    "However, `np.astype()` is safe to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594884b2-c4ca-4728-b9c6-c24e300428ce",
   "metadata": {},
   "source": [
    "**[2] Tuples**\n",
    "\n",
    "Methods which return tuples are supported, but it's recommended that you extract the elements in the tuple in different variables and don't continue working with the tuple as a whole to avoid hard-to-debug issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778aca7-0617-492f-985e-971b29e2fd2f",
   "metadata": {},
   "source": [
    "**[3] Methods that return new arrays**\\\n",
    "also valid for methods that extract an array (e.g. `np.diag`)\n",
    "\n",
    "Numpy methods that return new arrays (e.g. `np.pad()`), as well as methods that extract arrays (`e.g. np.diag()`) might cause issues, for the reason explained in \\[1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4b62c-0f29-4d2c-8a36-e384d626d9c2",
   "metadata": {},
   "source": [
    "**[4] NaN values**\n",
    "\n",
    "Pay attention to functions and operations which can return NaN, as this can show undefined behaviour. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8391a6-106c-4d0b-b73a-bc21842a341a",
   "metadata": {},
   "source": [
    "**[5] Metadata**\n",
    "\n",
    "TODO - but this is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4727435-e68b-440d-93f8-7168a519299f",
   "metadata": {},
   "source": [
    "**[6] Chaining operation, and using multiple operations in a line**\n",
    "\n",
    "Using multiple functions on the same line might not work as expected. For example, if you want to calculate `(n - n.mean()) / n.std()` it is advisable to compute the `std` and the `mean` separately, and then to compute the final result using the variables with the values from the standard deviation and the mean. \n",
    "\n",
    "Similarly, chaining multiple functions one after another might cause an error. For example, if you want to filter an array and then compute the average, it is advisable to do this in two different steps, rather than do it in a one-liner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c835dc-5117-4d26-ad1d-7fcf766684f0",
   "metadata": {},
   "source": [
    "**[7] In-place modifications**\n",
    "\n",
    "In-place modifications will cause a crash. Avoid usecases from the examples below:\n",
    "```\n",
    "mock_object += 1\n",
    "np.add(mock_object, mock_object, out=mock_object)\n",
    "np.sub(mock_object, mock_object, out=mock_object)\n",
    "np.multiply(mock_object, mock_object, out=mock_object)\n",
    "np.divide(mock_object, mock_object, out=mock_object)\n",
    "mock_object[mock_object > 0.5] *= 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb2771a-5b50-4a7a-9b69-116b180c5609",
   "metadata": {},
   "source": [
    "**[8] NumPy subclasses**\n",
    "\n",
    "For example, `np.random.shuffle(mock_object)` will show a warning and generate an incorrect result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e3cb0-dfb1-4dfd-9420-af0762f74503",
   "metadata": {},
   "source": [
    "**[9] Record arrays**\n",
    "\n",
    "Record arrays are not supported and using them will throw errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733bc1a-9244-4960-91ba-4de70efa9bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
