{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2fdd84-96be-4c5e-87ab-4276f0bdd17a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206f6e0-91e1-44c3-ae65-0acb3058dcd7",
   "metadata": {},
   "source": [
    "Welcome ðŸ‘‹!\n",
    "\n",
    "First of all, thank you for helping the world become more privacy-friendly by using PySyft. This notebook is primarily intended for **data scientists** and it will guide you into how to make use of all the capabilities PySyft has to offer in the latest version 0.8.\n",
    "\n",
    "This tutorial will cover three parts:\\\n",
    "(1) ðŸ‘‰ Understanding the workflow\\\n",
    "(2) ðŸ‘‰ How to send your first code request\\\n",
    "(3) ðŸ‘‰ What queries are supported in syft 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7086bb-61e0-4017-96a5-e25eb951c90d",
   "metadata": {},
   "source": [
    "## Part 1 - Understanding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a72b379-f686-4096-9487-2b6e8102bdf4",
   "metadata": {},
   "source": [
    "#### Context\n",
    "Let's imagine you want to do research into bubble tea trends because you want to open your own store. You found a dataset which contains the information you would need to answer your questions. The dataset is owned by a company and mentained by Amie, one of their employees. For this scenario, Amie has the role of **data manager**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ce136-38b7-49d5-9208-0f4d3b2cec61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The role of data managers\n",
    "Data managers are PySyft users who are responsible for datasets. They can upload, edit and remove datasets. Most importantly, a data manager is the person who is approving project requests and code submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5522e-144b-4389-9bff-5ef059c00e07",
   "metadata": {},
   "source": [
    "#### Project request\n",
    "Once you find Amie's dataset listed on the platform, you can submit a project request where you request access to the data. In your project request, you should include the reasons why you need access to the data, and any other trustworthy information that prove you have good intentions, such as university affiliation (this will increase your chances of getting your project request approved).\n",
    "\n",
    "We'll see how to submit a project request in part (2) of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b514164-a6bf-4d11-b48b-b709dc5a7669",
   "metadata": {},
   "source": [
    "#### Code request\n",
    "After your project request is approved, you will be able to submit code queries, which will allow you to learn from the data. A code query can be seen as a function which will give you a desired answer (for example, the average rating for a particular type of bubble tea drink, or the drink with the most sugar). We'll see how to send code queries in part (2) of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf20ba6-cdef-4cd5-81e2-21e66897fbcd",
   "metadata": {},
   "source": [
    "#### However...\n",
    "\n",
    "You won't directly have access to the data stored in the dataset. This is convenient for data managers, as they retain ownership of the data and prevent it from getting copied elsewhere. However, you will still be able to learn relevant statistical information from the dataset, even without having access to the data per se. This is good for data scientists like you, as you can still make use of the knowledge contained in the dataset and be able to advance your research. Win-win!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892610b3-897e-4ccf-9c3f-22ff8ce0b362",
   "metadata": {},
   "source": [
    "#### Real data and mock data\n",
    "\n",
    "How it works is that there will be two datasets:\n",
    "- the real dataset, containing the true unaltered information\n",
    "- a mock dataset, containing fake data generated to be of the same type and shape to the real one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9b001-1e4a-4a1b-b0c3-3e135ff97f81",
   "metadata": {},
   "source": [
    "#### High-side domain and low-side domain\n",
    "\n",
    "The real dataset will be kept private in what is called **the high side domain**. Only the data manager or other company employess will have direct access to it, and not data scientists.\n",
    "\n",
    "The mock dataset will be stored into the **low side domain** and you will have direct access to it via code request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32cf997-ec52-4689-a34c-3f07cc652aa0",
   "metadata": {},
   "source": [
    "#### Workflow altogether\n",
    "\n",
    "Let's assume Amie approved your project request to study the dataset, and now you can start learning from it via code requests.\n",
    "\n",
    "**Decide on a research question**\\\n",
    "First, what question do you want to answer? Let's imagine that you want the average rating for the brown sugar bubble milk tea, i.e. how liked it was overall by all customers who bought it.\n",
    "\n",
    "**Prepare the query** (purple arrows)\\\n",
    "What you know your goal, you will start by preparing the query. You will only work on the mock dataset, the one from the low-side domain. The dataset will look and feel like the real one, but it won't contain the true data. You can make use of this to write and test your query, to make sure that the code compiles properly and returns an answer. You can edit and test your code query as many times as you want.\n",
    "\n",
    "**Submit the code request** (orange arrows)\\\n",
    "One you are happy with the code query, then you can send it to be run on the real data. This is how you will get an accurate (but still privacy-friendly) answer for your research question. What happens here is that your code will be sent via PySyft API directly to the data manager (Amie, in this case). The data manager will check your code, make sure it is safe to be run on the real data, and if so, then they will execute your code on the private data, and generate the answer. This is why it's important that your code runs correctly when you decide to submit the code request - otherwise, the data manager will also be unable to run it and this will result in delays. \n",
    "\n",
    "**Get the answer** (orange arrows)\\\n",
    "After the data manager runs the code, they will also inspect the answer to make sure privacy is preserved if they share it with you. If all is fine, then they will send your the unaltered answer which your function returned on the private, real data. You will be notified when the answer is ready and will be able to retrieve this using the PySyft API.\n",
    "\n",
    "All the technical details will be explained in this tutorial, in part (2).\n",
    "\n",
    "*Note*: because getting the real answer involves manual checks and execution on behalf of the data manager, this means that often the data scientist won't receive the answer right away, but it might be hours or even days later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3409955-27d8-499e-a50b-668c8fa4d6d6",
   "metadata": {},
   "source": [
    "![Screenshot 2023-04-26 at 22.23.04.png](level-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef97895-7441-4ef8-8d0c-0c9fa2a102e1",
   "metadata": {},
   "source": [
    "## Part 5 - Queries supported in Syft 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f23a6e-90ce-4f95-a650-bbe518d80fb2",
   "metadata": {},
   "source": [
    "This part of the tutorial will briefly outline what is supported and not when using Syft. There are some limitations, as shown below, and this might result in errors when running the code request on the private data. This section will explain what to bear in mind when writing your code request, and how to adapt your code to the current Syft capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71088b5d-5435-4f80-9064-a4227ca53eff",
   "metadata": {},
   "source": [
    "**What is supported for NumPy?**\n",
    "\n",
    "- array creation\n",
    "- computing statistical information: `mean`, `std`, `min`, `max` etc\n",
    "- slicing and indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f281d0-7b82-443b-bb8e-aa66103ef91d",
   "metadata": {},
   "source": [
    "Generally, the most common operations for NumPy are also supported when using Syft. But here are some things which you should keep in mind when writing a code request:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb99e5-4c3e-4743-93ce-9c03a1b17167",
   "metadata": {},
   "source": [
    "**[1] Converting objects**\n",
    "\n",
    "`np.assarray(mock_object)`, `pd.DataFrame(mock_object)` and `torch.Tensor(mock_object)` will return objects which lose the Syft class associated to them, which is not desired. Avoid using them.\n",
    "\n",
    "However, `np.astype()` is safe to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e10ec-c7f7-4226-bd6d-f221c9737794",
   "metadata": {},
   "source": [
    "**[2] Tuples**\n",
    "\n",
    "Methods which return tuples are supported, but it's recommended that you extract the elements in the tuple in different variables and don't continue working with the tuple as a whole to avoid hard-to-debug issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fff249-f4f0-4525-b9c2-94565230b613",
   "metadata": {},
   "source": [
    "**[3] Methods that return new arrays**\n",
    "\n",
    "Numpy methods that return new arrays (e.g. `np.pad()`), as well as methods that extract arrays (e.g. `np.diag()`) might cause issues, for the reason explained in [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba33fd0-836a-4678-92f1-527366d9d054",
   "metadata": {},
   "source": [
    "**[4] NaN values**\n",
    "\n",
    "Pay attention to functions and operations which can return `NaN`, as this can show undefined behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4edbcd-38c9-4d02-8995-f1f59e4c2302",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[5] Metadata**\n",
    "\n",
    "TODO - but this is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fb41e-ad19-48a2-ad11-99915e7dc11c",
   "metadata": {},
   "source": [
    "**[6] Chaining operation, and using multiple operations in a line**\n",
    "\n",
    "Using multiple functions on the same line might not work as expected. For example, if you want to calculate `(n - n.mean()) / n.std()` it is advisable to compute the `std` and the `mean` separately, and then to compute the final result using the variables with the values from the standard deviation and the mean. \n",
    "\n",
    "Similarly, chaining multiple functions one after another might cause an error. For example, if you want to filter an array and then compute the average, it is advisable to do this in two different steps, rather than do it in a one-liner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31bdec-c02f-4e7c-940e-e25919c74c31",
   "metadata": {},
   "source": [
    "**[7] In-place modifications**\n",
    "\n",
    "In-place modifications will cause a crash. Avoid usecases from the examples below:\n",
    "```\n",
    "mock_object += 1\n",
    "np.add(mock_object, mock_object, out=mock_object)\n",
    "np.sub(mock_object, mock_object, out=mock_object)\n",
    "np.multiply(mock_object, mock_object, out=mock_object)\n",
    "np.divide(mock_object, mock_object, out=mock_object)\n",
    "mock_object[mock_object > 0.5] *= 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ffbec-56dc-4020-b049-7b8455a344fe",
   "metadata": {},
   "source": [
    "**[8] NumPy subclasses**\n",
    "\n",
    "For example, `np.random.shuffle(mock_object)` will show a warning and generate an incorrect result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d4663-5a41-4824-811a-b0bf839c620a",
   "metadata": {},
   "source": [
    "**[9] Record arrays**\n",
    "\n",
    "Record arrays are not supported and using them will throw errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5041e1-63e6-4070-abf8-472e3d170632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
